{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事前学習済みモデル\n",
    "PRETRAINED_MODEL_NAME = \"sonoisa/t5-base-japanese\"\n",
    "\n",
    "# 転移学習済みモデルを保存する場所\n",
    "MODEL_DIR = \"/content/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/neologd/mecab-ipadic-neologd/wiki/Regexp.ja から引用・一部改変\n",
    "from __future__ import unicode_literals\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def unicode_normalize(cls, s):\n",
    "    pt = re.compile('([{}]+)'.format(cls))\n",
    "\n",
    "    def norm(c):\n",
    "        return unicodedata.normalize('NFKC', c) if pt.match(c) else c\n",
    "\n",
    "    s = ''.join(norm(x) for x in re.split(pt, s))\n",
    "    s = re.sub('－', '-', s)\n",
    "    return s\n",
    "\n",
    "def remove_extra_spaces(s):\n",
    "    s = re.sub('[ 　]+', ' ', s)\n",
    "    blocks = ''.join(('\\u4E00-\\u9FFF',  # CJK UNIFIED IDEOGRAPHS\n",
    "                      '\\u3040-\\u309F',  # HIRAGANA\n",
    "                      '\\u30A0-\\u30FF',  # KATAKANA\n",
    "                      '\\u3000-\\u303F',  # CJK SYMBOLS AND PUNCTUATION\n",
    "                      '\\uFF00-\\uFFEF'   # HALFWIDTH AND FULLWIDTH FORMS\n",
    "                      ))\n",
    "    basic_latin = '\\u0000-\\u007F'\n",
    "\n",
    "    def remove_space_between(cls1, cls2, s):\n",
    "        p = re.compile('([{}]) ([{}])'.format(cls1, cls2))\n",
    "        while p.search(s):\n",
    "            s = p.sub(r'\\1\\2', s)\n",
    "        return s\n",
    "\n",
    "    s = remove_space_between(blocks, blocks, s)\n",
    "    s = remove_space_between(blocks, basic_latin, s)\n",
    "    s = remove_space_between(basic_latin, blocks, s)\n",
    "    return s\n",
    "\n",
    "def normalize_neologd(s):\n",
    "    s = s.strip()\n",
    "    s = unicode_normalize('０-９Ａ-Ｚａ-ｚ｡-ﾟ', s)\n",
    "\n",
    "    def maketrans(f, t):\n",
    "        return {ord(x): ord(y) for x, y in zip(f, t)}\n",
    "\n",
    "    s = re.sub('[˗֊‐‑‒–⁃⁻₋−]+', '-', s)  # normalize hyphens\n",
    "    s = re.sub('[﹣－ｰ—―─━ー]+', 'ー', s)  # normalize choonpus\n",
    "    s = re.sub('[~∼∾〜〰～]+', '〜', s)  # normalize tildes (modified by Isao Sonobe)\n",
    "    s = s.translate(\n",
    "        maketrans('!\"#$%&\\'()*+,-./:;<=>?@[¥]^_`{|}~｡､･｢｣',\n",
    "              '！”＃＄％＆’（）＊＋，－．／：；＜＝＞？＠［￥］＾＿｀｛｜｝〜。、・「」'))\n",
    "\n",
    "    s = remove_extra_spaces(s)\n",
    "    s = unicode_normalize('！”＃＄％＆’（）＊＋，－．／：；＜＞？＠［￥］＾＿｀｛｜｝〜', s)  # keep ＝,・,「,」\n",
    "    s = re.sub('[’]', '\\'', s)\n",
    "    s = re.sub('[”]', '\"', s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import re\n",
    "\n",
    "target_genres = [\"dokujo-tsushin\",\n",
    "                 \"it-life-hack\",\n",
    "                 \"kaden-channel\",\n",
    "                 \"livedoor-homme\",\n",
    "                 \"movie-enter\",\n",
    "                 \"peachy\",\n",
    "                 \"smax\",\n",
    "                 \"sports-watch\",\n",
    "                 \"topic-news\"]\n",
    "\n",
    "def remove_brackets(text):\n",
    "    text = re.sub(r\"(^【[^】]*】)|(【[^】]*】$)\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def normalize_text(text):\n",
    "    assert \"\\n\" not in text and \"\\r\" not in text\n",
    "    text = text.replace(\"\\t\", \" \")\n",
    "    text = text.strip()\n",
    "    text = normalize_neologd(text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def read_title_body(file):\n",
    "    next(file)\n",
    "    next(file)\n",
    "    title = next(file).decode(\"utf-8\").strip()\n",
    "    title = normalize_text(remove_brackets(title))\n",
    "    body = normalize_text(\" \".join([line.decode(\"utf-8\").strip() for line in file.readlines()]))\n",
    "    return title, body\n",
    "\n",
    "genre_files_list = [[] for genre in target_genres]\n",
    "\n",
    "all_data = []\n",
    "\n",
    "with tarfile.open(\"ldcc-20140209.tar.gz\") as archive_file:\n",
    "    for archive_item in archive_file:\n",
    "        for i, genre in enumerate(target_genres):\n",
    "            if genre in archive_item.name and archive_item.name.endswith(\".txt\"):\n",
    "                genre_files_list[i].append(archive_item.name)\n",
    "\n",
    "    for i, genre_files in enumerate(genre_files_list):\n",
    "        for name in genre_files:\n",
    "            file = archive_file.extractfile(name)\n",
    "            title, body = read_title_body(file)\n",
    "            title = normalize_text(title)\n",
    "            body = normalize_text(body)\n",
    "\n",
    "            if len(title) > 0 and len(body) > 0:\n",
    "                all_data.append({\n",
    "                    \"title\": title,\n",
    "                    \"body\": body,\n",
    "                    \"genre_id\": i\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/train.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17909/359391328.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtrain_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"data/train.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"data/dev.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf_dev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"data/test.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train.tsv'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "random.seed(1234)\n",
    "random.shuffle(all_data)\n",
    "\n",
    "def to_line(data):\n",
    "    title = data[\"title\"]\n",
    "    body = data[\"body\"]\n",
    "    genre_id = data[\"genre_id\"]\n",
    "\n",
    "    assert len(title) > 0 and len(body) > 0\n",
    "    return f\"{title}\\t{body}\\t{genre_id}\\n\"\n",
    "\n",
    "data_size = len(all_data)\n",
    "train_ratio, dev_ratio, test_ratio = 0.7, 0.15, 0.15\n",
    "\n",
    "with open(f\"data/train.tsv\", \"w\", encoding=\"utf-8\") as f_train, \\\n",
    "    open(f\"data/dev.tsv\", \"w\", encoding=\"utf-8\") as f_dev, \\\n",
    "    open(f\"data/test.tsv\", \"w\", encoding=\"utf-8\") as f_test:\n",
    "    \n",
    "    for i, data in tqdm(enumerate(all_data)):\n",
    "        line = to_line(data)\n",
    "        if i < train_ratio * data_size:\n",
    "            f_train.write(line)\n",
    "        elif i < (train_ratio + dev_ratio) * data_size:\n",
    "            f_dev.write(line)\n",
    "        else:\n",
    "            f_test.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd1e28d9b8f161f331e3b6c76987692a1c41a7261a9c401d9d6717c4d81bbcc7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
